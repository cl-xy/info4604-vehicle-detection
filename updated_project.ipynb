{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (3.18.1)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lu xinyi\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Installing collected packages: six\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "Successfully installed six-1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: textract 1.6.4 has requirement six~=1.12.0, but you'll have six 1.15.0 which is incompatible.\n",
      "ERROR: mlxtend 0.20.0 has requirement scikit-learn>=1.0.2, but you'll have scikit-learn 1.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 # pip install opencv-python\n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras \n",
    "from glob import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization,MaxPool2D,Dense,Conv2D,Flatten\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_dir = 'data/vehicles/'\n",
    "non_vehicle_dir = 'data/non-vehicles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_names = os.listdir(vehicle_dir)\n",
    "non_vehicle_names = os.listdir(non_vehicle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Explore the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of vehicle images: 8792\n",
      "No of non-vehicle images: 8968\n"
     ]
    }
   ],
   "source": [
    "print(\"No of vehicle images:\", len(vehicle_names))\n",
    "print(\"No of non-vehicle images:\", len(non_vehicle_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Prepare the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = {\n",
    "    'non-vehicles': 0,\n",
    "    'vehicles': 1\n",
    "}\n",
    "\n",
    "# get all the paths for vehicles and non-vehicles\n",
    "def get_paths(folder):\n",
    "    \n",
    "    path = []\n",
    "    labels = []\n",
    "    for dirname, _, filenames in os.walk(folder):\n",
    "        dir_class = dirname.split('/')[1] # either vehicles or non-vehicles\n",
    "        for filename in filenames:\n",
    "            path.append(os.path.join(dirname, filename))\n",
    "            labels.append(cat[dir_class])\n",
    "    \n",
    "    return pd.DataFrame({'path': path, 'class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/vehicles/10.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/1000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/vehicles/1001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/1002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     path  class\n",
       "0     data/vehicles/1.png      1\n",
       "1    data/vehicles/10.png      1\n",
       "2  data/vehicles/1000.png      1\n",
       "3  data/vehicles/1001.png      1\n",
       "4  data/vehicles/1002.png      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_df = get_paths(vehicle_dir)\n",
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/non-vehicles/extra1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/extra10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/non-vehicles/extra100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/extra1000.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/non-vehicles/extra1001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  class\n",
       "0     data/non-vehicles/extra1.png      0\n",
       "1    data/non-vehicles/extra10.png      0\n",
       "2   data/non-vehicles/extra100.png      0\n",
       "3  data/non-vehicles/extra1000.png      0\n",
       "4  data/non-vehicles/extra1001.png      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_vehicles_df = get_paths(non_vehicle_dir)\n",
    "non_vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([vehicles_df, non_vehicles_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/vehicles/10.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/1000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/vehicles/1001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/1002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     path  class\n",
       "0     data/vehicles/1.png      1\n",
       "1    data/vehicles/10.png      1\n",
       "2  data/vehicles/1000.png      1\n",
       "3  data/vehicles/1001.png      1\n",
       "4  data/vehicles/1002.png      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/3519.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/image604.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/5546.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/image525.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/far (574).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path  class\n",
       "0          data/vehicles/3519.png      1\n",
       "1  data/non-vehicles/image604.png      0\n",
       "2          data/vehicles/5546.png      1\n",
       "3  data/non-vehicles/image525.png      0\n",
       "4     data/vehicles/far (574).png      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle dataset using sample\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/3519.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/image604.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/5546.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/image525.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/far (574).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17755</th>\n",
       "      <td>data/non-vehicles/extra334.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17756</th>\n",
       "      <td>data/non-vehicles/image575.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17757</th>\n",
       "      <td>data/vehicles/5675.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17758</th>\n",
       "      <td>data/non-vehicles/extra4531.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17759</th>\n",
       "      <td>data/vehicles/1210.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  path  class\n",
       "0               data/vehicles/3519.png      1\n",
       "1       data/non-vehicles/image604.png      0\n",
       "2               data/vehicles/5546.png      1\n",
       "3       data/non-vehicles/image525.png      0\n",
       "4          data/vehicles/far (574).png      1\n",
       "...                                ...    ...\n",
       "17755   data/non-vehicles/extra334.png      0\n",
       "17756   data/non-vehicles/image575.png      0\n",
       "17757           data/vehicles/5675.png      1\n",
       "17758  data/non-vehicles/extra4531.png      0\n",
       "17759           data/vehicles/1210.png      1\n",
       "\n",
       "[17760 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we sampled the first 200 rows to start out\n",
    "sample_df = df.iloc[:, :] # if you want to sample just the first 200 rows do -> sample_df = df.iloc[:200, :]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8968\n",
       "1    8792\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths, img_size):\n",
    "    images = []\n",
    "    \n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, img_size) #resize the images\n",
    "        img = np.array(img)\n",
    "        \n",
    "        images.append(img)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.int64)\n",
    "    \n",
    "    #scale images\n",
    "#     images = images/255\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17760, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "images = load_images(sample_df['path'], (64, 64))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = images\n",
    "y = sample_df[\"class\"]\n",
    "\n",
    "#train test split - 75% train, 25% test\n",
    "\n",
    "x_training, x_test = x[:13320,:], x[13320:,:]\n",
    "y_training, y_test = y[:13320], y[13320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13320, 64, 64, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4440, 64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13320,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4440,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(13320,), dtype=int64, numpy=array([1, 0, 1, ..., 0, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increases accuracy (even when not using loss function) \n",
    "tf.cast(x_training, tf.int64)\n",
    "tf.cast(y_training, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Build the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "vehicle_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(64, 64, 3)),\n",
    "#     tf.keras.layers.Dense(16, activation='sigmoid', # first hidden layer has 16 inputs, each nodes activation will be a sigmoid function \n",
    "#                           name='fc1', input_shape=(64, 64, 3)), \n",
    "#     tf.keras.layers.Dense(3, name='fc2', activation='relu')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Train the Model & 6. Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "417/417 [==============================] - 6s 11ms/step - loss: 54.3669 - accuracy: 0.8135\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 12.1726 - accuracy: 0.8786: 0s - loss: 13.1698 - acc\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 5.4757 - accuracy: 0.8900 0s - loss: 5.4867 - accuracy: 0.88\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 1.9251 - accuracy: 0.9086\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4845 - accuracy: 0.9122\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2908 - accuracy: 0.9029\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2597 - accuracy: 0.8962\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2508 - accuracy: 0.9098\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1980 - accuracy: 0.9286 0s - loss: 0.1986 - accu\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1853 - accuracy: 0.9289\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2656 - accuracy: 0.8830\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2003 - accuracy: 0.9233\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.7583 - accuracy: 0.8659\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2771 - accuracy: 0.9279\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2341 - accuracy: 0.9289\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2131 - accuracy: 0.9306\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2037 - accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2026 - accuracy: 0.9324 0s - los\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2090 - accuracy: 0.9273\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2857 - accuracy: 0.9029\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1964 - accuracy: 0.9357\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2410 - accuracy: 0.9215\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1830 - accuracy: 0.9411\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2605 - accuracy: 0.9084\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2659 - accuracy: 0.9071\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.3056 - accuracy: 0.8941 0s - loss:\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2368 - accuracy: 0.9185 0s - los\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2230 - accuracy: 0.9239\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2295 - accuracy: 0.9221\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2047 - accuracy: 0.9327\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1863 - accuracy: 0.9386\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2198 - accuracy: 0.9267\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2266 - accuracy: 0.9224\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2135 - accuracy: 0.9306\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2084 - accuracy: 0.9288\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.1888 - accuracy: 0.9382\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.2171 - accuracy: 0.9322\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.2138 - accuracy: 0.9289\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.3780 - accuracy: 0.8833\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1899 - accuracy: 0.9379\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1863 - accuracy: 0.9411\n",
      "Epoch 42/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2216 - accuracy: 0.9275\n",
      "Epoch 43/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1733 - accuracy: 0.9445\n",
      "Epoch 44/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1891 - accuracy: 0.9369\n",
      "Epoch 45/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2016 - accuracy: 0.9330\n",
      "Epoch 46/50\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1926 - accuracy: 0.9378\n",
      "Epoch 47/50\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.4363 - accuracy: 0.8745\n",
      "Epoch 48/50\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1850 - accuracy: 0.9421\n",
      "Epoch 49/50\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1781 - accuracy: 0.9433\n",
      "Epoch 50/50\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1906 - accuracy: 0.9378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20296bfb460>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_model.fit(x_training, y_training, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_model.compile(optimizer='sgd', \n",
    "#               loss=\"mse\",\n",
    "#               metrics=['mae', 'mse', 'acc'])\n",
    "# vehicle_model.fit(x_training, y_training, \n",
    "#                   epochs = 100, \n",
    "#                   batch_size = 5,\n",
    "#                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vehicle_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mvehicle_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      2\u001b[0m y_pred\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vehicle_model' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = vehicle_model.predict(x_test)\n",
    "y_pred\n",
    "# this crashes the kernel because our sample size is so large when not trying to use all images we got an accuracy of 97.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555/555 - 4s - loss: 0.1654 - accuracy: 0.9473\n"
     ]
    }
   ],
   "source": [
    "test_loss = vehicle_model.evaluate(x,  y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([vehicle_model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.279019e-01, 7.202491e-02, 7.326257e-05], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: the first prediction. \n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions returns a number for each class which represents the probability of it being in that class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13320, 12288)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM takes 2D input to train\n",
    "X_train = np.array(x_training).reshape(len(x_training), -1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13320,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4440, 12288)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(x_test).reshape(len(x_test), -1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "svc = SVC(probability=True)\n",
    "svc.fit(X_train, y_training)\n",
    "y_pred2 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977027027027027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out how many images we want to process for predictions so kernel doesn't crash, model works\n",
    "#accuracy and loss function (what do we mean by loss function and can we still cast?)\n",
    "#plot a few images\n",
    "#add more observations and headers that match the assignment outline delete commented code (how do we interpret the predictions?)\n",
    "#cite sources (like which parts are based off of his code)\n",
    "#we can make our code even more exactly like the process he used (I'm fine not doing that tho) and \n",
    "\n",
    "#DONE - changed sample size to the entire batch instead of a small sample (it's still 75% training) \n",
    "#DONE - standardization --> resizing of image (32, 32) (64 by 64 should be good, it's more detailed). \n",
    "    # we also don't need to divide by 266 because it's not a monochrome image\n",
    "#DONE - keras model accuracy - 0.9\n",
    "    # can mess with batch size (didn't need to)\n",
    "    # changed to relu activation\n",
    "    # increased epochs to 50 instead of 10\n",
    "    \n",
    "#DONE - svm model accuracy - 0.98"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
