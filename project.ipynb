{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 05:51:50.792443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 05:51:50.971680: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-17 05:51:50.983191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-17 05:51:50.983228: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-17 05:51:51.017346: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-17 05:51:51.696226: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-17 05:51:51.696374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-17 05:51:51.696388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 # pip install opencv-python\n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras \n",
    "from glob import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization,MaxPool2D,Dense,Conv2D,Flatten\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_dir = 'data/vehicles/'\n",
    "non_vehicle_dir = 'data/non-vehicles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_names = os.listdir(vehicle_dir)\n",
    "non_vehicle_names = os.listdir(non_vehicle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Explore the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of vehicle images: 8792\n",
      "No of non-vehicle images: 8968\n"
     ]
    }
   ],
   "source": [
    "print(\"No of vehicle images:\", len(vehicle_names))\n",
    "print(\"No of non-vehicle images:\", len(non_vehicle_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Prepare the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = {\n",
    "    'non-vehicles': 0,\n",
    "    'vehicles': 1\n",
    "}\n",
    "\n",
    "# get all the paths for vehicles and non-vehicles\n",
    "def get_paths(folder):\n",
    "    \n",
    "    path = []\n",
    "    labels = []\n",
    "    for dirname, _, filenames in os.walk(folder):\n",
    "        dir_class = dirname.split('/')[1] # either vehicles or non-vehicles\n",
    "        for filename in filenames:\n",
    "            path.append(os.path.join(dirname, filename))\n",
    "            labels.append(cat[dir_class])\n",
    "    \n",
    "    return pd.DataFrame({'path': path, 'class': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/left (739).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/vehicles/far (366).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/far (644).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/vehicles/1884.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/5462.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  class\n",
       "0  data/vehicles/left (739).png      1\n",
       "1   data/vehicles/far (366).png      1\n",
       "2   data/vehicles/far (644).png      1\n",
       "3        data/vehicles/1884.png      1\n",
       "4        data/vehicles/5462.png      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_df = get_paths(vehicle_dir)\n",
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/non-vehicles/extra2371.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/image2890.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/non-vehicles/extra643.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/image3162.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/non-vehicles/image3303.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  class\n",
       "0  data/non-vehicles/extra2371.png      0\n",
       "1  data/non-vehicles/image2890.png      0\n",
       "2   data/non-vehicles/extra643.png      0\n",
       "3  data/non-vehicles/image3162.png      0\n",
       "4  data/non-vehicles/image3303.png      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_vehicles_df = get_paths(non_vehicle_dir)\n",
    "non_vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([vehicles_df, non_vehicles_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/left (739).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/vehicles/far (366).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/far (644).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/vehicles/1884.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/5462.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  class\n",
       "0  data/vehicles/left (739).png      1\n",
       "1   data/vehicles/far (366).png      1\n",
       "2   data/vehicles/far (644).png      1\n",
       "3        data/vehicles/1884.png      1\n",
       "4        data/vehicles/5462.png      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/5854.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/extra2563.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/far (236).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/image3515.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/1632.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  class\n",
       "0           data/vehicles/5854.png      1\n",
       "1  data/non-vehicles/extra2563.png      0\n",
       "2      data/vehicles/far (236).png      1\n",
       "3  data/non-vehicles/image3515.png      0\n",
       "4           data/vehicles/1632.png      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle dataset using sample\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/vehicles/5854.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/non-vehicles/extra2563.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/vehicles/far (236).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/non-vehicles/image3515.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/vehicles/1632.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>data/vehicles/684.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>data/non-vehicles/extra2991.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>data/non-vehicles/image2464.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>data/vehicles/1394.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>data/vehicles/far (830).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path  class\n",
       "0             data/vehicles/5854.png      1\n",
       "1    data/non-vehicles/extra2563.png      0\n",
       "2        data/vehicles/far (236).png      1\n",
       "3    data/non-vehicles/image3515.png      0\n",
       "4             data/vehicles/1632.png      1\n",
       "..                               ...    ...\n",
       "195            data/vehicles/684.png      1\n",
       "196  data/non-vehicles/extra2991.png      0\n",
       "197  data/non-vehicles/image2464.png      0\n",
       "198           data/vehicles/1394.png      1\n",
       "199      data/vehicles/far (830).png      1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample for 200 rows first\n",
    "sample_df = df.iloc[:200, :]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    101\n",
       "0     99\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths, img_size):\n",
    "    images = []\n",
    "    \n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, img_size) #resize the images\n",
    "        img = np.array(img)\n",
    "        \n",
    "        images.append(img)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.int64)\n",
    "    \n",
    "    #scale images\n",
    "    images = images/255\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "images = load_images(sample_df['path'], (64, 64))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = images\n",
    "y = sample_df[\"class\"]\n",
    "\n",
    "#train test split - 75% train, 25% test\n",
    "x_training, x_test = x[:150,:], x[150:,:]\n",
    "y_training, y_test = y[:150], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 64, 64, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 05:51:54.745061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-17 05:51:54.745133: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-17 05:51:54.745198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-cyli6138): /proc/driver/nvidia/version does not exist\n",
      "2022-11-17 05:51:54.745849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150,), dtype=int64, numpy=\n",
       "array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increases accuracy (even when not using loss function) \n",
    "tf.cast(x_training, tf.int64)\n",
    "tf.cast(y_training, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Build the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid', # first hidden layer has 16 inputs, each nodes activation will be a sigmoid function \n",
    "                          name='fc1', input_shape=(64, 64, 3)), \n",
    "    tf.keras.layers.Dense(3, name='fc2', activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 16)                196624    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,675\n",
      "Trainable params: 196,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vehicle_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Train the Model & 6. Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.2953 - mae: 0.5156 - mse: 0.2953 - acc: 0.4733\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2943 - mae: 0.5156 - mse: 0.2943 - acc: 0.4600\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2940 - mae: 0.5156 - mse: 0.2940 - acc: 0.4533\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2938 - mae: 0.5156 - mse: 0.2938 - acc: 0.4267\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2937 - mae: 0.5156 - mse: 0.2937 - acc: 0.4067\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2936 - mae: 0.5156 - mse: 0.2936 - acc: 0.3867\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3733\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3533\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3533\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3467\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3400\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3400\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2935 - mae: 0.5156 - mse: 0.2935 - acc: 0.3400\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3333\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3533\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3400\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3333\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3400\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3533\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3333\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3600\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3400\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3400\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2867\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2867\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3333\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3200\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2800\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2800\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2733\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2867\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2867\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3133\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3400\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3067\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3000\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.3267\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2934 - mae: 0.5156 - mse: 0.2934 - acc: 0.2933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ad07c5510>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_model.compile(optimizer='sgd', \n",
    "              loss=\"mse\",\n",
    "              metrics=['mae', 'mse', 'acc'])\n",
    "vehicle_model.fit(x_training, y_training, \n",
    "                  epochs = 100, \n",
    "                  batch_size = 1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.35240367, 0.31623143, 0.33136484],\n",
       "       [0.34726664, 0.31010678, 0.3426266 ],\n",
       "       [0.3293499 , 0.3508907 , 0.3197593 ],\n",
       "       [0.33133316, 0.33629394, 0.33237284],\n",
       "       [0.3317996 , 0.31992763, 0.3482727 ],\n",
       "       [0.34148225, 0.31932512, 0.3391926 ],\n",
       "       [0.33788165, 0.32083353, 0.34128478],\n",
       "       [0.35115826, 0.31435674, 0.3344849 ],\n",
       "       [0.33350545, 0.33678207, 0.3297124 ],\n",
       "       [0.30976358, 0.34344846, 0.3467879 ],\n",
       "       [0.3077073 , 0.38070872, 0.311584  ],\n",
       "       [0.3444301 , 0.31841817, 0.33715162],\n",
       "       [0.31009838, 0.34884477, 0.34105676],\n",
       "       [0.32991993, 0.3423212 , 0.3277589 ],\n",
       "       [0.34217373, 0.32816765, 0.32965863],\n",
       "       [0.3449406 , 0.32060048, 0.33445898],\n",
       "       [0.3436453 , 0.32759058, 0.32876417],\n",
       "       [0.33134755, 0.33301574, 0.33563673],\n",
       "       [0.33980158, 0.3250239 , 0.33517456],\n",
       "       [0.339564  , 0.33070424, 0.32973185],\n",
       "       [0.3369444 , 0.3211484 , 0.34190714],\n",
       "       [0.337246  , 0.32782137, 0.3349326 ],\n",
       "       [0.33360225, 0.34773612, 0.31866163],\n",
       "       [0.32859161, 0.33616066, 0.3352476 ],\n",
       "       [0.33075187, 0.3311389 , 0.33810925],\n",
       "       [0.33373496, 0.3348722 , 0.33139282],\n",
       "       [0.33609846, 0.32733202, 0.33656943],\n",
       "       [0.33445174, 0.33304626, 0.3325021 ],\n",
       "       [0.32744884, 0.3352841 , 0.33726698],\n",
       "       [0.3519425 , 0.33093837, 0.31711915],\n",
       "       [0.33094725, 0.33772275, 0.33132997],\n",
       "       [0.3277115 , 0.33120242, 0.34108612],\n",
       "       [0.3305579 , 0.32204902, 0.3473931 ],\n",
       "       [0.32141712, 0.33583978, 0.34274307],\n",
       "       [0.33987805, 0.32893482, 0.33118716],\n",
       "       [0.33153626, 0.33422074, 0.33424294],\n",
       "       [0.32898828, 0.32916757, 0.34184408],\n",
       "       [0.33145598, 0.3229425 , 0.3456015 ],\n",
       "       [0.33187708, 0.32252255, 0.34560034],\n",
       "       [0.33687857, 0.32860693, 0.3345146 ],\n",
       "       [0.34049213, 0.3261325 , 0.3333754 ],\n",
       "       [0.33652642, 0.3294077 , 0.3340659 ],\n",
       "       [0.33447903, 0.34621835, 0.31930256],\n",
       "       [0.34215742, 0.3328925 , 0.32495007],\n",
       "       [0.34714764, 0.31840748, 0.3344449 ],\n",
       "       [0.33294958, 0.32801965, 0.33903062],\n",
       "       [0.3381158 , 0.324528  , 0.33735618],\n",
       "       [0.32991302, 0.346238  , 0.3238489 ],\n",
       "       [0.3172304 , 0.33582416, 0.34694543],\n",
       "       [0.3496944 , 0.33125186, 0.31905368]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = vehicle_model.predict(x_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.2795 - mae: 0.5017 - mse: 0.2795 - acc: 0.3100 - 367ms/epoch - 52ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss = vehicle_model.evaluate(x,  y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([vehicle_model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = probability_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3397137 , 0.32764506, 0.33264118], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: the first prediction. \n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions returns a number for each class which represents the probability of it being in that class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
